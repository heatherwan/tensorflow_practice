{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 8us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 30s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 4s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  48  88  54  25  19   0   0   0   0   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  4   1   1   1   0   0 206 204 106 163 178 157 163 171 119  39   0   0\n",
      "    2   1   1   1   1   1   1   1   0   0]\n",
      " [  0   0   0   0   0  84 204   0   0   0   1  57  91  77  99 138  94   7\n",
      "    0   0   0   0   0   0   0   0   1   3]\n",
      " [ 51  43  27  27  28 254  31   0   4   0   0   0  16 121  84  19  63 110\n",
      "   31   0   0   0   0   0   0   0   0   0]\n",
      " [137 202 133 108  97 146  71  78  82  86  85 105 118 139 143 126 162 176\n",
      "  135  69  76  71  91  99 103  94  99  54]\n",
      " [  0 110 186 205 203 193 191 178 204 172 175 175 177 183 189 190 197 196\n",
      "  192 182 186 185 184 182 178 168 159  77]\n",
      " [  0   0   0   4  51  69  92 108 112 115 112 111 112  90  77  62  44  36\n",
      "   32  35  27  25  19  14   5   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 30\n",
    "plt.imshow(training_images[n])\n",
    "print(training_labels[n])\n",
    "print(training_images[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "training_images = training_images/255\n",
    "test_images = test_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(), \n",
    "                             keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                             keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2305 - acc: 0.9128\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2235 - acc: 0.9167\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2197 - acc: 0.9170\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2158 - acc: 0.9193\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2113 - acc: 0.9199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x13d78e3c8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3498920034110546, 0.8843]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4208086e-08 9.9999964e-01 1.6130777e-10 2.4181531e-07 1.4746708e-08\n",
      " 1.3801929e-15 6.1043714e-08 1.1614105e-22 1.6216953e-12 1.5283608e-19]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "print(classification[n])\n",
    "print(test_labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(), \n",
    "                             keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                             keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.5286 - acc: 0.8147\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3992 - acc: 0.8574\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3647 - acc: 0.8680\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3403 - acc: 0.8776\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3190 - acc: 0.8831\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3059 - acc: 0.8881\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2951 - acc: 0.8909\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2843 - acc: 0.8948\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2753 - acc: 0.8973\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2660 - acc: 0.9018\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2576 - acc: 0.9041\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2508 - acc: 0.9069: 1s - loss\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2466 - acc: 0.9080\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2407 - acc: 0.9095: 0s - loss: 0.2385 - acc\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2324 - acc: 0.9140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x13d787a90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3426906922698021, 0.8808]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.4737\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.3595\n",
      "\n",
      "Reached 60% accuracy so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x13eba2da0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('loss')<0.4):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
